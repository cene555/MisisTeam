import imageio.v3 as iio
import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io


animation_options = [
    None,
    'right', 'left',
    'up', 'down',
    'spin_clockwise', 'spin_counterclockwise',
    'zoomin', 'zoomout',
    'rotate_right', 'rotate_left',
    'rotate_up', 'rotate_down',
    'around_right', 'around_left',
    'zoomin_sinus_x', 'zoomout_sinus_y',
    'right_sinus_y', 'left_sinus_y',
    'live'
]

def generate_image(prompt, text, user_image, image_size=(768, 768)):
    return Image.open("test.jpg").resize(image_size)

def generate_video():
    return Image.open("test.mp4")

def create_tab_1_2(tab_key, image_size):
    imageLocation = st.empty()
    st.session_state[f"{tab_key}_text"] = st.text_input(
        "—Ç–µ–∫—Å—Ç –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ", 
        value="–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞", 
        max_chars=50, 
        key=f"{tab_key}_text_input"
        )
    st.session_state[f"{tab_key}_prompt"] = st.text_input(
        "–ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–∞–Ω–Ω–µ—Ä–∞", 
        key=f"{tab_key}_prompt_text"
        )
    st.selectbox(
        "–ê–Ω–∏–º–∞—Ü–∏—è", 
        options=animation_options, 
        index=0, 
        key=f"{tab_key}_animation_selectbox"
        )
    
    init_image_upload = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏ —Ñ–æ—Ç–æ –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", 
        type=["png", "jpg", "jpeg"], 
        accept_multiple_files=False,
        key=f"{tab_key}_init_image_upload"
        )

    if init_image_upload is not None:
        st.session_state[f"{tab_key}_init_image"] = Image.open(
            io.BytesIO(init_image_upload.getvalue())
            )
    else: 
        st.session_state[f"{tab_key}_init_image"] = Image.fromarray(
            (np.random.random(size=image_size) * 255).astype(np.uint8)
            )

    imageLocation.image(
        st.session_state[f"{tab_key}_init_image"], 
        width=image_size[1]
        )

    user_image_upload = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏ —Å–≤–æ–µ —Ñ–æ—Ç–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", 
        type=["png", "jpg", "jpeg"], 
        accept_multiple_files=False,
        key=f"{tab_key}_user_image_upload"
        )
    if user_image_upload:
        st.session_state[f"{tab_key}_user_image"] = Image.open(
            io.BytesIO(user_image_upload.getvalue())
        )
    else: 
        st.session_state[f"{tab_key}_user_image"] = None

def create_tab_3(tab_key, image_size):
    imageLocation = st.empty()
    st.session_state[f"{tab_key}_text"] = st.text_input(
        "—Ç–µ–∫—Å—Ç –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ", 
        value="–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞", 
        max_chars=50, 
        key=f"{tab_key}_text_input"
        )
    st.session_state[f"{tab_key}_prompt"] = st.text_input(
        "–ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–∞–Ω–Ω–µ—Ä–∞", 
        key=f"{tab_key}_prompt_text"
        )

    st.selectbox(
        "–ê–Ω–∏–º–∞—Ü–∏—è", 
        options=animation_options, 
        index=0, 
        key=f"{tab_key}_animation_selectbox"
        )
    
    init_video_upload = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏ –≤–∏–¥–µ–æ", 
        type=["mp4"], 
        accept_multiple_files=False,
        key=f"{tab_key}_init_image_upload"
        )

    frame_skip = 1 # display every 300 frames

    if init_video_upload is not None: # run only when user uploads video
        if init_video_upload is not None: # run only when user uploads video
            vid = init_video_upload.name
            with open(vid, mode='wb') as f:
                f.write(init_video_upload.read()) # save video to disk
            vidcap = cv2.VideoCapture(vid) # load video from disk
            cur_frame = 0
            success = True
            frames = []

            while success:
                success, frame = vidcap.read() # get next frame from video
                if cur_frame % frame_skip == 0 and success: # only analyze every n=300 frames
                    print('frame: {}'.format(cur_frame)) 
                    pil_img = Image.fromarray(frame[:, :, ::-1]) # convert opencv frame (with type()==numpy) into PIL Image
                    frames.append(pil_img)
                    imageLocation.image(
                        pil_img, 
                        width=image_size[1]
                    )
                cur_frame += 1

    st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å!", key=f"{tab_key}_generate_button", on_click=None)

user_data = dict()
tab1, tab2, tab3 = st.tabs(["–ë–∞–Ω–Ω–µ—Ä üåá", "–ê–≤–∞—Ç–∞—Ä üóø", "–ü—Ä–µ–≤—å—é –≤–∏–¥–µ–æ üé•"])

with tab1:
    tab_key = "banner"
    st.title("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ë–∞–Ω–Ω–µ—Ä–∞ üåá")
    create_tab_1_2(tab_key, (400, 800, 3))

with tab2:
    tab_key = "avatar"
    st.title("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ê–≤–∞—Ç–∞—Ä–∞ üóø")
    create_tab_1_2(tab_key, (800, 800, 3))
    
with tab3:
    tab_key = "preview"
    st.title("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ü—Ä–µ–≤—å—é –≤–∏–¥–µ–æ üé•")
    create_tab_3(tab_key, (400, 800, 3))